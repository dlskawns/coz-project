{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CP2_Bigdata_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeiMGaWC08ixSfN7C5USLX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlskawns/coz-project/blob/main/CP2_Bigdata_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 빅데이터 분석\n",
        "\n",
        "빅데이터를 다루기 위한 방법들을 알아봅시다.  \n",
        "빅데이터란 무엇일까요? 말 그대로 '큰 데이터'를 의미합니다.  \n",
        "\n",
        "정보, 데이터의 활용과 그 가치가 높아짐에 따라 많은 기업들부터 개인까지 각자 용도에 맞는 정보를 수집하는 시대에 살고 있습니다.   \n",
        "그만큼 많은 정보들을 담다보면 그 크기가 굉장히 커지고, 불필요하게 많아지기도 해서 데이터 분석에 어려움을 겪게 될 수 있습니다. \n",
        "\n",
        "굉장히 큰 데이터를 처리할 때, 어떤 방법들을 활용할 수 있는지 알아봅시다.\n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "DoKKtnXN-3ST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 데이터를 쪼개어 살펴보기\n",
        "\n",
        "* 데이터가 너무 클 경우엔 데이터를 찾고자 하는 부분에 맞추어 국소적으로 관찰해 볼 수 있습니다.  \n",
        "* 특정 문제에 대한 가설을 바탕으로 작은 단위의 문제로 만들어 진행한 뒤, 각각의 결과를 바탕으로 인사이트를 얻을 수 있습니다.\n",
        "  * 예를 들어 국가 사업 또는 국가 관련 정보를 바탕으로 문제를 정의하여 분석고자 한다면, 찾고자 하는 문제에 가장 영향력 있는 몇 개의 국가를 찾아 해당 국가 별 판매량 등 세부적인 정보를 파악합니다.\n",
        "  * 또한 찾은 판매량 중에서도 높은 카테고리가 있다거나, 유독 높거나 적은 판매량을 보이는 날짜 등을 파악해 특징을 파악합니다. \n",
        "  * 이러한 방식으로 데이터를 작은 단위로 쪼개어서 깊게 파고들어 인사이트를 확보합니다.\n",
        "\n",
        "#### 예시)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VnbpWEpk__gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 데이터의 경량화\n",
        "\n",
        "* 데이터 샘플링\n",
        "  * 데이터가 너무 큰 경우, 다양한 방식으로 샘플링 해서 진행할 수 있습니다.\n",
        "* 메모리 최적화: \n",
        "  * 데이터 파일을 효율적으로 활용할 수 있도록 메모리를 줄여봅니다.\n",
        "  * 데이터 코드화: object -> int 등\n",
        "  * 데이터 형식 변환: 가능한 적은 byte로 줄이기 / object -> category, int64 -> int32\n",
        "  * 파일 포맷 변환: parquet ,hdf5 등\n",
        "* 그 외 방법\n",
        "  * 데이터의 경량화는 아니지만, 파이썬 자체의 내장함수를 잘 조합해서 활용하면 훨씬 빠르게 활용할 수 있는 함수들이 있습니다. \n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "vPOCtomT__5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. 빅데이터 처리 플랫폼 활용\n",
        "다양한 빅데이터 처리 플랫폼들이 서비스를 제공하고 있습니다.  \n",
        "이러한 플랫폼의 서비스를 활용해서 좀 더 빠르고 간편하게 데이터 분석을 진행해볼 수도 있습니다.  \n",
        "\n",
        "다만, 해당 플랫폼의 서비스를 활용하기 위해선 튜토리얼 등을 어느정도 익힐 필요가 있습니다.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "lqQMaARz18ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) Apache Spark\n",
        "\n",
        "대규모 데이터 처리용 통합 분석 엔진입니다.  \n",
        "SQL, 스트리밍, 머신러닝 및 그래프 처리를 위한 기본. 제공 모듈을 제공합니다.\n",
        "\n",
        "데이터\n",
        "\n",
        "\n",
        "#### 2) Google Cloud Platform"
      ],
      "metadata": {
        "id": "MqTOddk43D7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFkhBLxT6pHB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}